{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11388625,"sourceType":"datasetVersion","datasetId":7131738},{"sourceId":11401561,"sourceType":"datasetVersion","datasetId":7141197},{"sourceId":11406941,"sourceType":"datasetVersion","datasetId":7145338},{"sourceId":336829,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":281855,"modelId":302735},{"sourceId":336879,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":281888,"modelId":302766},{"sourceId":337420,"sourceType":"modelInstanceVersion","isSourceIdPinned":false,"modelInstanceId":282266,"modelId":303139},{"sourceId":338154,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":282770,"modelId":303635}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers\n!pip install datasets\n!pip install peft\n!pip install evaluate\n!pip install tqdm\n!pip install torch\n!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n!pip install bert_score\n!pip install sacrebleu","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-15T13:18:40.035088Z","iopub.execute_input":"2025-04-15T13:18:40.035406Z","iopub.status.idle":"2025-04-15T13:20:43.797581Z","shell.execute_reply.started":"2025-04-15T13:18:40.035382Z","shell.execute_reply":"2025-04-15T13:20:43.795992Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->transformers) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->transformers) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->transformers) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->transformers) (2024.2.0)\nRequirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (19.0.1)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.3)\nRequirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\nRequirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\nCollecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.16)\nRequirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->datasets) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->datasets) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->datasets) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->datasets) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->datasets) (2024.2.0)\nDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: fsspec\n  Attempting uninstall: fsspec\n    Found existing installation: fsspec 2025.3.2\n    Uninstalling fsspec-2025.3.2:\n      Successfully uninstalled fsspec-2025.3.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ngcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\ntorch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed fsspec-2024.12.0\nRequirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (7.0.0)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\nRequirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.5.1+cu124)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.51.1)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\nRequirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from peft) (1.3.0)\nRequirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.2)\nRequirement already satisfied: huggingface-hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.30.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (3.18.0)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2024.12.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (2.32.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.25.0->peft) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->peft) (2.4.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.13.0->peft)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.13.0->peft)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.13.0->peft)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.13.0->peft)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.13.0->peft)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.13.0->peft)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.13.0->peft)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->peft) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->peft) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->peft) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.25.0->peft) (2025.1.31)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->peft) (2024.2.0)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m65.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.3)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.12.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.30.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.18.0)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (19.0.1)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.16)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.2.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.19.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nLooking in indexes: https://download.pytorch.org/whl/cu118\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.20.1+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\nCollecting bert_score\n  Downloading bert_score-0.3.13-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.5.1+cu124)\nRequirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.2.3)\nRequirement already satisfied: transformers>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.51.1)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from bert_score) (1.26.4)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from bert_score) (2.32.3)\nRequirement already satisfied: tqdm>=4.31.1 in /usr/local/lib/python3.11/dist-packages (from bert_score) (4.67.1)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from bert_score) (3.7.5)\nRequirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from bert_score) (24.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.1->bert_score) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->bert_score) (2.4.1)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2024.12.0)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.3.1.170)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (12.4.127)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.0.0->bert_score) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.0.0->bert_score) (1.3.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.30.2)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (2024.11.6)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.21.0)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=3.0.0->bert_score) (0.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (4.56.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (1.4.8)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (11.1.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->bert_score) (3.2.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->bert_score) (2025.1.31)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.1->bert_score) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.0.0->bert_score) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->bert_score) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->bert_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->bert_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->bert_score) (2024.2.0)\nDownloading bert_score-0.3.13-py3-none-any.whl (61 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: bert_score\nSuccessfully installed bert_score-0.3.13\nCollecting sacrebleu\n  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting portalocker (from sacrebleu)\n  Downloading portalocker-3.1.1-py3-none-any.whl.metadata (8.6 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (2024.11.6)\nRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.9.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (1.26.4)\nRequirement already satisfied: colorama in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (0.4.6)\nRequirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from sacrebleu) (5.3.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.17->sacrebleu) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.17->sacrebleu) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->sacrebleu) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.17->sacrebleu) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.17->sacrebleu) (2024.2.0)\nDownloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading portalocker-3.1.1-py3-none-any.whl (19 kB)\nInstalling collected packages: portalocker, sacrebleu\nSuccessfully installed portalocker-3.1.1 sacrebleu-2.5.1\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport torch\nimport shutil\nfrom datasets import load_dataset, Dataset\nfrom transformers import BartTokenizer, BartForConditionalGeneration, TrainingArguments, Trainer\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom evaluate import load\nfrom tqdm import tqdm\n\n# # BART + LORA code\n\n# remove existing adapter directory if it exists\nif os.path.exists(\"./bart-optimized\"):\n    shutil.rmtree(\"./bart-optimized\")\n\n# set cuda memory configuration\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\ntorch.cuda.empty_cache()\n\n# load evaluation metrics\nbleu = load(\"sacrebleu\")\nbertscore = load(\"bertscore\")\n\n# load tokenizer and model\nmodel_name = \"facebook/bart-large-cnn\"\ntokenizer = BartTokenizer.from_pretrained(model_name)\nbase_model = BartForConditionalGeneration.from_pretrained(model_name)\n\n# configure lora\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1\n)\nmodel = get_peft_model(base_model, peft_config)\n\n# load dataset\ndataset = load_dataset(\"json\", data_files={\n    \"train\": \"/kaggle/input/nlp-project/train_project.json\",\n    \"val\": \"/kaggle/input/nlp-project/valid_project.json\",\n    \"test\": \"/kaggle/input/nlp-project/test_project.json\"\n})\n\n# define target summary labels\nperspectives = [\"INFORMATION\", \"SUGGESTION\", \"EXPERIENCE\", \"QUESTION\", \"CAUSE\"]\n\n# clean invalid or placeholder summary values\ndef clean_summary(text):\n    if not text or not isinstance(text, str):\n        return \"\"\n    stripped = text.strip()\n    if stripped.lower() in [\"false\", \"true\", \"not_duplicate\", \"n/a\", \"duplicate\", \"\"]:\n        return \"\"\n    return stripped\n\n# format examples into model input-output pairs\ndef format_example(example):\n    input_text = (\n        f\"Context: {example.get('context', '').strip()}\\n\"\n        f\"Question: {example.get('question', '').strip()}\\n\"\n        f\"Answers: {' '.join(example.get('answers', [])).strip()}\"\n    )\n    labelled_summaries = example.get(\"labelled_summaries\", {})\n    output_lines = []\n    for label in perspectives:\n        summary = clean_summary(labelled_summaries.get(f\"{label}_SUMMARY\", \"\"))\n        if not summary:\n            summary = \"No summary available.\"\n        output_lines.append(f\"{label} SUMMARY: {summary}\")\n    return {\"input\": input_text.strip(), \"output\": \"\\n\".join(output_lines).strip()}\n\n# format datasets\ntrain_data = [format_example(ex) for ex in tqdm(dataset[\"train\"], desc=\"formatting train\")]\nval_data   = [format_example(ex) for ex in tqdm(dataset[\"val\"], desc=\"formatting val\")]\ntest_data  = [format_example(ex) for ex in tqdm(dataset[\"test\"], desc=\"formatting test\")]\n\ntrain_dataset = Dataset.from_list(train_data)\nval_dataset   = Dataset.from_list(val_data)\ntest_dataset  = Dataset.from_list(test_data)\n\n# tokenize and encode datasets\ndef preprocess(examples):\n    inputs = tokenizer(examples[\"input\"], padding=\"max_length\", max_length=512, truncation=True)\n    targets = tokenizer(examples[\"output\"], padding=\"max_length\", max_length=256, truncation=True)\n    inputs[\"labels\"] = [\n        [(token if token != tokenizer.pad_token_id else -100) for token in label]\n        for label in targets[\"input_ids\"]\n    ]\n    return inputs\n\ntrain_tok = train_dataset.map(preprocess, batched=True)\nval_tok = val_dataset.map(preprocess, batched=True)\ntest_tok = test_dataset.map(preprocess, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T11:24:07.825122Z","iopub.execute_input":"2025-04-14T11:24:07.825400Z","iopub.status.idle":"2025-04-14T11:24:33.047168Z","shell.execute_reply.started":"2025-04-14T11:24:07.825380Z","shell.execute_reply":"2025-04-14T11:24:33.046609Z"}},"outputs":[{"name":"stderr","text":"Formatting train: 100%|██████████| 2236/2236 [00:00<00:00, 5752.69it/s]\nFormatting val: 100%|██████████| 959/959 [00:00<00:00, 5937.09it/s]\nFormatting test: 100%|██████████| 640/640 [00:00<00:00, 5798.37it/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2236 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17a297c988c545a7826efc4e2362aa4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/959 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a0dac80ffb449b0901bb5dfc3ac3bfb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/640 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b91920ce96034de48def165956535dd0"}},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"print(train_tok[0])\n# print(dataset[\"train\"][0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T12:50:29.882880Z","iopub.execute_input":"2025-04-14T12:50:29.883146Z","iopub.status.idle":"2025-04-14T12:50:29.889462Z","shell.execute_reply.started":"2025-04-14T12:50:29.883131Z","shell.execute_reply":"2025-04-14T12:50:29.888682Z"}},"outputs":[{"name":"stdout","text":"{'input': 'Context: \\nQuestion: what is parkinesonism?\\nAnswers: u spelt it wrong !!\\nParkinson\\'s disease is one of the most common neurologic disorders of the elderly. The term \"parkinsonism\" refers to any condition that causes any combination of the types of movement abnormalities seen in Parkinson\\'s disease by damaging or destroying dopamine neurons in a certain area of the brain. Parkinsonism describes the common symptoms of Parkinson\\'s disease - tremor, rigidity, akinesia or bradykinesia and postural instability. Those patients who respond to drug treatment for Parkinson\\'s disease are diagnosed with it, and those who do not have parkinsonism.', 'output': 'INFORMATION SUMMARY: Parkinson\\'s disease is a prevalent neurologic disorder among the elderly. The term \"parkinsonism\" encompasses any condition leading to movement abnormalities similar to those observed in Parkinson\\'s disease. This condition arises from the damage or destruction of dopamine neurons in a specific brain region. Common symptoms of parkinsonism include tremors, rigidity, akinesia or bradykinesia, and postural instability. Diagnosis of Parkinson\\'s disease is established in patients responding to drug treatments, while those who do not respond are categorized under parkinsonism.\\nSUGGESTION SUMMARY: No summary available.\\nEXPERIENCE SUMMARY: No summary available.\\nQUESTION SUMMARY: No summary available.\\nCAUSE SUMMARY: No summary available.', 'input_ids': [0, 48522, 35, 1437, 50118, 45641, 35, 99, 16, 2221, 3141, 261, 1809, 116, 50118, 4688, 48792, 35, 1717, 2292, 6607, 24, 1593, 43912, 50118, 25130, 9554, 18, 2199, 16, 65, 9, 5, 144, 1537, 31649, 636, 12876, 9, 5, 7497, 4, 20, 1385, 22, 15129, 9554, 1809, 113, 12859, 7, 143, 1881, 14, 4685, 143, 4069, 9, 5, 3505, 9, 2079, 39063, 450, 11, 18475, 18, 2199, 30, 9055, 50, 14340, 40965, 28449, 11, 10, 1402, 443, 9, 5, 2900, 4, 18475, 1809, 7448, 5, 1537, 5298, 9, 18475, 18, 2199, 111, 6110, 15188, 6, 10727, 35714, 6, 18735, 3141, 493, 50, 5378, 8772, 330, 3141, 493, 8, 618, 9799, 16826, 4, 2246, 1484, 54, 2519, 7, 1262, 1416, 13, 18475, 18, 2199, 32, 6443, 19, 24, 6, 8, 167, 54, 109, 45, 33, 2221, 9554, 1809, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [0, 2444, 48436, 29214, 448, 10760, 35, 18475, 18, 2199, 16, 10, 18689, 31649, 636, 8364, 566, 5, 7497, 4, 20, 1385, 22, 15129, 9554, 1809, 113, 27747, 143, 1881, 981, 7, 2079, 39063, 1122, 7, 167, 6373, 11, 18475, 18, 2199, 4, 152, 1881, 28125, 31, 5, 1880, 50, 8181, 9, 40965, 28449, 11, 10, 2167, 2900, 976, 4, 9732, 5298, 9, 2221, 9554, 1809, 680, 33704, 994, 6, 10727, 35714, 6, 18735, 3141, 493, 50, 5378, 8772, 330, 3141, 493, 6, 8, 618, 9799, 16826, 4, 23465, 13310, 9, 18475, 18, 2199, 16, 2885, 11, 1484, 6827, 7, 1262, 8289, 6, 150, 167, 54, 109, 45, 2519, 32, 31658, 223, 2221, 9554, 1809, 4, 50118, 104, 13644, 534, 4923, 7744, 29214, 448, 10760, 35, 440, 4819, 577, 4, 50118, 6725, 21260, 41499, 29214, 448, 10760, 35, 440, 4819, 577, 4, 50118, 46392, 7744, 29214, 448, 10760, 35, 440, 4819, 577, 4, 50118, 4054, 27291, 29214, 448, 10760, 35, 440, 4819, 577, 4, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n","output_type":"stream"}],"execution_count":61},{"cell_type":"code","source":"from math import ceil\nfrom transformers import TrainingArguments, Trainer\nimport os\nfrom tqdm.auto import tqdm \n\n# disable wandb logging\nos.environ[\"WANDB_DISABLED\"] = \"true\"\n\n# define batch size\ntrain_batch_size = 4\n\n# set training arguments\ntraining_args = TrainingArguments(\n    output_dir=\"./bart-optimized\",\n    do_eval=True,\n    eval_steps=None,  # will be set after initialization\n    save_strategy=\"epoch\",\n    per_device_train_batch_size=train_batch_size,\n    per_device_eval_batch_size=4,\n    num_train_epochs=10,\n    gradient_accumulation_steps=2,\n    save_total_limit=2,\n    logging_steps=50,\n    fp16=False,\n    local_rank=-1,\n    label_names=[\"labels\"],  # required for peft models\n    logging_dir=\"./logs\",\n    report_to=[]  # prevent integration with external loggers\n)\n\n# compute evaluation steps based on dataset size\neval_steps = ceil(len(train_tok) / train_batch_size)\ntraining_args.eval_steps = eval_steps\n\n# initialize trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_tok,\n    eval_dataset=val_tok,\n    tokenizer=tokenizer\n)\n\n# start training - with tqdm\ntrainer.train()\n\n# BART + LORA MODEL SAVED\n# save final model and tokenizer\nmodel.save_pretrained(\"./bart-optimized\")\ntokenizer.save_pretrained(\"./bart-optimized\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:37:09.678534Z","iopub.execute_input":"2025-04-14T07:37:09.678836Z","iopub.status.idle":"2025-04-14T07:37:10.420004Z","shell.execute_reply.started":"2025-04-14T07:37:09.678814Z","shell.execute_reply":"2025-04-14T07:37:10.419439Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_31/2525023933.py:35: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import os\nimport torch\nfrom transformers import BartTokenizer, BartForConditionalGeneration\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom evaluate import load\nfrom tqdm.auto import tqdm\nfrom datasets import load_dataset\n\n# EVALUATING BART + LORA MODEL\n\n# setting device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# specifying path to the trained model\nmodel_path = \"/kaggle/input/bart-optimized/pytorch/default/1\"\n\n# loading tokenizer and base model\ntokenizer = BartTokenizer.from_pretrained(model_path)\nbase_model = BartForConditionalGeneration.from_pretrained(model_path)\n\n# configuring lora for inference\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    inference_mode=True,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1\n)\nmodel = get_peft_model(base_model, peft_config)\nmodel.to(device)\nmodel.eval()\n\n# defining list of target perspectives\nperspectives = [\"INFORMATION\", \"SUGGESTION\", \"EXPERIENCE\", \"QUESTION\", \"CAUSE\"]\n\n# generating summary for each perspective\ndef generate_summary(input_text):\n    summaries = {}\n    for perspective in perspectives:\n        prompt = (\n            f\"Generate a {perspective} summary:\\n\"\n            f\"{input_text}\\n\"\n            f\"Provide a clear and structured {perspective.lower()} summary.\"\n        )\n        input_ids = tokenizer(\n            prompt,\n            return_tensors=\"pt\",\n            truncation=True,\n            max_length=512\n        ).input_ids.to(device)\n        output_ids = model.generate(input_ids=input_ids, max_length=150, num_beams=5)\n        generated = tokenizer.decode(output_ids[0], skip_special_tokens=True).strip()\n        summaries[perspective] = generated\n    return summaries\n\n# parsing reference summaries from formatted output\ndef parse_reference(output_text):\n    refs = {}\n    for line in output_text.strip().split(\"\\n\"):\n        if \"SUMMARY:\" in line:\n            parts = line.split(\"SUMMARY:\", 1)\n            if len(parts) == 2:\n                label = parts[0].strip().split()[0].upper()\n                summary = parts[1].strip()\n                if summary not in [\"False\", \"True\", \"No summary available.\"]:\n                    refs[label] = summary\n    return refs\n\n# loading evaluation metrics\nbleu = load(\"sacrebleu\")\nbertscore = load(\"bertscore\")\n\n# evaluating model using bleu and bertscore\ndef evaluate(dataset, name=\"test\"):\n    results = {p: {\"references\": [], \"predictions\": []} for p in perspectives}\n    for ex in tqdm(dataset, desc=f\"evaluating {name}\"):\n        ref = parse_reference(ex[\"output\"])\n        pred = generate_summary(ex[\"input\"])\n        for p in perspectives:\n            if p in ref:\n                results[p][\"references\"].append([ref[p]])\n                results[p][\"predictions\"].append(pred[p])\n    for p in perspectives:\n        refs = results[p][\"references\"]\n        preds = results[p][\"predictions\"]\n        if refs and preds:\n            bleu_score = bleu.compute(predictions=preds, references=refs)[\"score\"]\n            bert_result = bertscore.compute(predictions=preds, references=[r[0] for r in refs], lang=\"en\")\n            bert_avg = sum(bert_result[\"f1\"]) / len(bert_result[\"f1\"])\n            print(f\"{p} - BLEU: {bleu_score:.8f}, BERTScore: {bert_avg:.4f}\")\n        else:\n            print(f\"{p} - not having enough data.\")\n\n# saving generated predictions to file\ndef save_predictions(dataset, file=\"bart_test_predictions.txt\"):\n    with open(file, \"w\") as f:\n        for ex in tqdm(dataset, desc=\"saving predictions\"):\n            f.write(\"INPUT:\\n\" + ex[\"input\"] + \"\\n\\n\")\n            pred = generate_summary(ex[\"input\"])\n            for p in perspectives:\n                f.write(f\"{p} SUMMARY:\\n{pred[p]}\\n\\n\")\n            f.write(\"-\" * 80 + \"\\n\")\n\n# evaluating and saving predictions\nevaluate(test_dataset, \"test\")\nsave_predictions(test_dataset, \"bart_test_predictions.txt\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:37:30.073903Z","iopub.execute_input":"2025-04-14T07:37:30.074678Z","iopub.status.idle":"2025-04-14T07:37:34.156202Z","shell.execute_reply.started":"2025-04-14T07:37:30.074652Z","shell.execute_reply":"2025-04-14T07:37:34.155659Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/peft/config.py:162: UserWarning: Unexpected keyword arguments ['alpha_pattern', 'bias', 'corda_config', 'eva_config', 'exclude_modules', 'fan_in_fan_out', 'init_lora_weights', 'layer_replication', 'layers_pattern', 'layers_to_transform', 'loftq_config', 'lora_alpha', 'lora_bias', 'lora_dropout', 'megatron_config', 'megatron_core', 'modules_to_save', 'r', 'rank_pattern', 'target_modules', 'trainable_token_indices', 'use_dora', 'use_rslora'] for class PeftConfig, these are ignored. This probably means that you're loading a configuration file that was saved using a higher version of the library and additional parameters have been introduced since. It is highly recommended to upgrade the PEFT version before continuing (e.g. by running `pip install -U peft`).\n  warnings.warn(\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"from evaluate import load\nfrom tqdm import tqdm\nimport torch\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\n# # FIND HARD EXAMPLES FROM THE TRAINING DATATSET FOR FINE TUNING - ADVERSARIAL MODEL\n\nbleu = load(\"bleu\")\nbertscore = load(\"bertscore\")\n\n\n# check if a sample is hard based on BLEU or BERTScore\ndef is_hard_example(pred, ref, threshold=0.84, metric=\"bertscore\"):\n    if metric == \"bleu\":\n        score = bleu.compute(predictions=[pred], references=[[ref]])[\"score\"] / 100\n    else:\n        score = bertscore.compute(predictions=[pred], references=[ref], lang=\"en\", device=device)[\"f1\"][0]\n        # print(score)\n    return score < threshold\n\n# count=0\n# get all hard examples from a dataset\ndef get_hard_examples(dataset, perspectives, threshold=0.84, metric=\"bertscore\"):\n    hard_inputs = []\n    for ex in tqdm(dataset, desc=\"Mining Hard Examples\"):\n        ref_summaries = parse_reference(ex[\"output\"])\n        gen_summaries = generate_summary(ex[\"input\"])\n        for p in perspectives:\n            if p in ref_summaries:\n                if is_hard_example(gen_summaries[p], ref_summaries[p], threshold, metric):\n                    # count+=1\n                    hard_inputs.append(ex)\n                    break  # At least one hard perspective is enough\n    print(f\"Total Hard Examples: {len(hard_inputs)}\")\n    return Dataset.from_list(hard_inputs)\n\n\n# identify hard examples\n# val_subset = random.sample(list(val_dataset), int(len(val_dataset)))\n\nhard_train_set = get_hard_examples(train_dataset, perspectives)\n\n# print(count)\n\nprint(f\"Total hard examples found: {len(hard_train_set)}\")\n\n# convert to list (only safe for small datasets)\n\n# # save hard examples\nDataset.from_list(hard_train_set).to_json(\"hard_train_examples.json\", indent=2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T07:37:39.965133Z","iopub.execute_input":"2025-04-14T07:37:39.965902Z","iopub.status.idle":"2025-04-14T11:20:33.951100Z","shell.execute_reply.started":"2025-04-14T07:37:39.965876Z","shell.execute_reply":"2025-04-14T11:20:33.950450Z"}},"outputs":[{"name":"stderr","text":"Mining Hard Examples:   0%|          | 0/2236 [00:00<?, ?it/s]Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nMining Hard Examples: 100%|██████████| 2236/2236 [3:42:51<00:00,  5.98s/it]  ","output_type":"stream"},{"name":"stdout","text":"Total Hard Examples: 598\nTotal hard examples found: 598\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Creating json from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9e3345e461b4acb971290a1303f5908"}},"metadata":{}},{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"1530230"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"from datasets import Dataset\nimport json\n\n\n# loading data from a text file containing JSON lines\ndef load_data(file_path):\n    examples = []\n    with open(file_path, 'r') as file:\n        content = file.readlines()\n        # parsing each line as a JSON object with 'input' and 'output' fields\n        for line in content:\n            try:\n                example = json.loads(line)\n                examples.append(example)\n            except json.JSONDecodeError:\n                continue\n    return examples\n\n# converting the list of examples into a HuggingFace Dataset\nhard_examples = load_data('/kaggle/input/hard-textfile/hard_examples.txt')\nhard_train_set = Dataset.from_dict({\n    \"input\": [example['input'] for example in hard_examples],\n    \"output\": [example['output'] for example in hard_examples]\n})\n\n# applying preprocessing to the dataset\ndef preprocess(examples):\n    model_inputs = tokenizer(examples[\"input\"], padding=\"max_length\", max_length=512, truncation=True)\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(examples[\"output\"], padding=\"max_length\", max_length=256, truncation=True)\n\n    # replacing padding tokens with -100 to ignore in loss computation\n    model_inputs[\"labels\"] = [\n        [(label if label != tokenizer.pad_token_id else -100) for label in labels_seq]\n        for labels_seq in labels[\"input_ids\"]\n    ]\n    return model_inputs\n\n# mapping preprocessing function over the dataset\nhard_tok = hard_train_set.map(preprocess, batched=True)\n\n# now hard_tok is containing the preprocessed tokenized dataset\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T12:17:26.113129Z","iopub.execute_input":"2025-04-14T12:17:26.113415Z","iopub.status.idle":"2025-04-14T12:17:26.185540Z","shell.execute_reply.started":"2025-04-14T12:17:26.113396Z","shell.execute_reply":"2025-04-14T12:17:26.184918Z"}},"outputs":[],"execution_count":38},{"cell_type":"code","source":"import json\nimport re\n\n\n# CONVERTEDF THE HARD_TRAIN_EXAMPLES.JSON FILE TO TXT MANUALLY (there was some issue with the fjson object formatting)\n# THEN CONVERTING THE TXT FILE TO JSON FILE AGAIN - CONVERTED_OUTPUT.JSON and using it for further work\n\ndef extract_json_objects_from_text(file_path):\n    with open(file_path, 'r', encoding='utf-8') as f:\n        text = f.read()\n\n    pattern = re.compile(r'\\{\\s*\"input\"\\s*:.*?\"output\"\\s*:.*?\\}', re.DOTALL)\n    matches = pattern.findall(text)\n\n    json_objects = []\n    for match in matches:\n        try:\n            json_obj = json.loads(match)\n            json_objects.append(json_obj)\n        except json.JSONDecodeError as e:\n            print(f\"Skipping malformed JSON object: {e}\")\n            continue\n\n    return json_objects\n\ndef convert_txt_to_json(input_txt_path, output_json_path):\n    data = extract_json_objects_from_text(input_txt_path)\n   \n    with open(output_json_path, 'w', encoding='utf-8') as f:\n        json.dump(data, f, indent=4, ensure_ascii=False)\n\n    print(f\"Converted {len(data)} examples to {output_json_path}\")\n\nconvert_txt_to_json(\"/kaggle/input/hard-textfile/hard_examples.txt\", \"converted_output.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T12:19:06.686246Z","iopub.execute_input":"2025-04-14T12:19:06.686994Z","iopub.status.idle":"2025-04-14T12:19:06.739651Z","shell.execute_reply.started":"2025-04-14T12:19:06.686968Z","shell.execute_reply":"2025-04-14T12:19:06.739053Z"}},"outputs":[{"name":"stdout","text":"Converted 598 examples to converted_output.json\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# load and preprocess hard examples\nhard_dataset = load_dataset(\"json\", data_files={\"train\": \"/kaggle/working/converted_output.json\"})[\"train\"]\n\n# print(hard_dataset[0])\n\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"input\"],\n        max_length=512,\n        padding=\"max_length\",\n        truncation=True,\n    )\n\n    # tokenize teh targets\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"output\"],\n            max_length=256,\n            padding=\"max_length\",\n            truncation=True,\n        )\n\n    # replace pad token ids in labels with -100 (for ignoring in loss)\n    labels_input_ids = labels[\"input_ids\"]\n    labels_input_ids = [\n        [(l if l != tokenizer.pad_token_id else -100) for l in label_seq]\n        for label_seq in labels_input_ids\n    ]\n\n    model_inputs[\"labels\"] = labels_input_ids\n    return model_inputs\n\n\ntokenized_hard_dataset = hard_dataset.map(preprocess_function, batched=True)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T12:39:25.433583Z","iopub.execute_input":"2025-04-14T12:39:25.434416Z","iopub.status.idle":"2025-04-14T12:39:30.171733Z","shell.execute_reply.started":"2025-04-14T12:39:25.434389Z","shell.execute_reply":"2025-04-14T12:39:30.171128Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/598 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a7c17c704cc498cbe1f32ad19697225"}},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"print(tokenized_hard_dataset[0])\n# print(val_tok[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T12:34:34.536796Z","iopub.execute_input":"2025-04-14T12:34:34.537299Z","iopub.status.idle":"2025-04-14T12:34:34.542379Z","shell.execute_reply.started":"2025-04-14T12:34:34.537279Z","shell.execute_reply":"2025-04-14T12:34:34.541523Z"}},"outputs":[{"name":"stdout","text":"{'input': \"Context: My mom always told me that I talk a lot in my sleep and sometimes I wake up shouting too, but recently my husband told me that every alternate night I start fighting with someone or the other - in very loud tones and most of the time I also swear and abuse the person I'm fighting with.\\n\\nThis is really freaking me out and I dont remember who I fight with or what I dream, but this also disturbs him and we dont have kids yet, but what will my babies think of me when they hear all kinds of profanity from their mommy's mouthwhile she's in dreamland! \\n\\nI need to make it stop but I dont even know where to begin. Somebody?\\nQuestion: I scream, shout and swear in my sleep. How do I stop?\\nAnswers: hmm i would say duck tape but thats a lil to extreme tell your husband to record you one day and then you guys watch the tape and if you think its needed take it to a Psyc Dr to see what he thinks shove a sock in your mouth marry as soon as possible heavy drugs I think that you have a stress on your daily life. I think that is not bad to do some following things, If you caould find any way, you will be happy, otherwise, you have to go to a psyc.\\n1) Keep out yourself from stress, during your day.\\n2) Try to sleep, just when you are really tired. (excuse me for this example!) Like after a sweet sex! try to find that are you in this situation after sex, or not? If No, it shows that you try to sleep, before it needs.\\n3) Read Book, or newsletter before sleep.\\n4) Drink one glass warm (NOT HOT) milk.\\n5) Do some sort of excersice before sleeping.\\n6) If you have any problem in your dream, try to solve it by someone that you are fighting with. I mean, before your sleeping (Specially when your husband is not at home, because I want to nobody awake you) try to solve your problem with your dream fighter!! Yes, it is funny but true. Try to find a logical way for treating out this conflict with your dream.\\n\\ni wish a good dream and sweet night, beside of your sweet husband. go to the doctors and ask if you should take sleeping tablets, this shouting may be because of bad sleep. Take light dinner in the night.Don't watch violent programes on Tv before sleep.Also if you became irritated in the day with some one discuss it in the home.Also heavy work load in the evening make this,just as heavy exercise.\\ntry to pray before sleep.These may help. Try taking 500 mg to 1,000 mg of magnesium at night.  It's a muscle and mind relaxer and will help you get a more restful night's sleep.\", 'output': \"INFORMATION SUMMARY: Magnesium is a muscle and mind relaxer which can help give you a more restful night's sleep.\\nSUGGESTION SUMMARY: It is suggested to use duct tape to record yourself, and then review the tape with your husband to assess if seeking advice from a psychiatrist is necessary. If you find difficulty sleeping, consider various strategies such as managing stress, ensuring tiredness before sleep, reading, drinking warm milk, exercising, and attempting to resolve dream conflicts. Seeking professional guidance for sleeping issues, including the possibility of taking sleeping tablets or magnesium supplements, may be beneficial. Additionally, it is recommended to avoid violent TV programs before bedtime, address irritations from the day, manage heavy workloads, and pray before sleep as part of a holistic approach to improving sleep quality.\\nEXPERIENCE SUMMARY: No summary available.\\nQUESTION SUMMARY: No summary available.\\nCAUSE SUMMARY: Shouting during sleep may be due to bad sleep or stress.\", 'input_ids': [0, 48522, 35, 1308, 3795, 460, 174, 162, 14, 38, 1067, 10, 319, 11, 127, 3581, 8, 2128, 38, 3874, 62, 14487, 350, 6, 53, 682, 127, 1623, 174, 162, 14, 358, 14417, 363, 38, 386, 2190, 19, 951, 50, 5, 97, 111, 11, 182, 7337, 23225, 8, 144, 9, 5, 86, 38, 67, 24909, 8, 2134, 5, 621, 38, 437, 2190, 19, 4, 50118, 50118, 713, 16, 269, 33432, 162, 66, 8, 38, 33976, 2145, 54, 38, 1032, 19, 50, 99, 38, 3366, 6, 53, 42, 67, 46584, 4311, 123, 8, 52, 33976, 33, 1159, 648, 6, 53, 99, 40, 127, 7272, 206, 9, 162, 77, 51, 1798, 70, 6134, 9, 8546, 30854, 31, 49, 3795, 4783, 18, 6085, 20235, 79, 18, 11, 3366, 1245, 328, 1437, 50118, 50118, 100, 240, 7, 146, 24, 912, 53, 38, 33976, 190, 216, 147, 7, 1642, 4, 34229, 116, 50118, 45641, 35, 38, 22093, 6, 18066, 8, 24909, 11, 127, 3581, 4, 1336, 109, 38, 912, 116, 50118, 4688, 48792, 35, 1368, 5471, 939, 74, 224, 15223, 7898, 53, 45365, 10, 38101, 7, 5004, 1137, 110, 1623, 7, 638, 47, 65, 183, 8, 172, 47, 1669, 1183, 5, 7898, 8, 114, 47, 206, 63, 956, 185, 24, 7, 10, 41391, 438, 925, 7, 192, 99, 37, 4265, 34940, 10, 37390, 11, 110, 6085, 12908, 25, 1010, 25, 678, 2016, 2196, 38, 206, 14, 47, 33, 10, 3992, 15, 110, 1230, 301, 4, 38, 206, 14, 16, 45, 1099, 7, 109, 103, 511, 383, 6, 318, 47, 6056, 25513, 465, 143, 169, 6, 47, 40, 28, 1372, 6, 3680, 6, 47, 33, 7, 213, 7, 10, 43114, 438, 4, 50118, 134, 43, 7238, 66, 2512, 31, 3992, 6, 148, 110, 183, 4, 50118, 176, 43, 11087, 7, 3581, 6, 95, 77, 47, 32, 269, 7428, 4, 36, 34645, 3698, 162, 13, 42, 1246, 13278, 2011, 71, 10, 4045, 2099, 328, 860, 7, 465, 14, 32, 47, 11, 42, 1068, 71, 2099, 6, 50, 45, 116, 318, 440, 6, 24, 924, 14, 47, 860, 7, 3581, 6, 137, 24, 782, 4, 50118, 246, 43, 1163, 5972, 6, 50, 3476, 137, 3581, 4, 50118, 306, 43, 24319, 65, 4049, 3279, 36, 37049, 33466, 43, 5803, 4, 50118, 245, 43, 1832, 103, 2345, 9, 12562, 268, 2463, 137, 8416, 4, 50118, 401, 43, 318, 47, 33, 143, 936, 11, 110, 3366, 6, 860, 7, 6136, 24, 30, 951, 14, 47, 32, 2190, 19, 4, 38, 1266, 6, 137, 110, 8416, 36, 104, 45674, 77, 110, 1623, 16, 45, 23, 184, 6, 142, 38, 236, 7, 5907, 24628, 47, 43, 860, 7, 6136, 110, 936, 19, 110, 3366, 7251, 12846, 3216, 6, 24, 16, 6269, 53, 1528, 4, 11087, 7, 465, 10, 16437, 169, 13, 8959, 66, 42, 3050, 19, 110, 3366, 4, 50118, 50118, 118, 2813, 10, 205, 3366, 8, 4045, 363, 6, 13276, 9, 110, 4045, 1623, 4, 213, 7, 5, 3333, 8, 1394, 114, 47, 197, 185, 8416, 12079, 6, 42, 14487, 189, 28, 142, 9, 1099, 3581, 4, 4624, 1109, 3630, 11, 5, 363, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [0, 2444, 48436, 29214, 448, 10760, 35, 3771, 45684, 16, 10, 8698, 8, 1508, 12327, 254, 61, 64, 244, 492, 47, 10, 55, 1079, 2650, 363, 18, 3581, 4, 50118, 104, 13644, 534, 4923, 7744, 29214, 448, 10760, 35, 85, 16, 2528, 7, 304, 29259, 7898, 7, 638, 2512, 6, 8, 172, 1551, 5, 7898, 19, 110, 1623, 7, 7118, 114, 1818, 2949, 31, 10, 27321, 16, 2139, 4, 318, 47, 465, 9600, 8416, 6, 1701, 1337, 4964, 215, 25, 4196, 3992, 6, 6060, 7428, 1825, 137, 3581, 6, 2600, 6, 4835, 3279, 5803, 6, 20203, 6, 8, 6475, 7, 5728, 3366, 9549, 4, 9402, 2038, 3824, 13, 8416, 743, 6, 217, 5, 3302, 9, 602, 8416, 12079, 50, 36165, 19619, 6, 189, 28, 10142, 4, 6903, 6, 24, 16, 5131, 7, 1877, 4153, 1012, 1767, 137, 3267, 958, 6, 1100, 26570, 1635, 31, 5, 183, 6, 3616, 2016, 16942, 29, 6, 8, 10745, 137, 3581, 25, 233, 9, 10, 23015, 1548, 7, 3927, 3581, 1318, 4, 50118, 6725, 21260, 41499, 29214, 448, 10760, 35, 440, 4819, 577, 4, 50118, 46392, 7744, 29214, 448, 10760, 35, 440, 4819, 577, 4, 50118, 4054, 27291, 29214, 448, 10760, 35, 840, 25754, 148, 3581, 189, 28, 528, 7, 1099, 3581, 50, 3992, 4, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"import os\nimport torch\nfrom math import ceil\nfrom tqdm.auto import tqdm\nfrom datasets import load_dataset, Dataset\nfrom transformers import BartTokenizer, BartForConditionalGeneration, TrainingArguments, Trainer\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom safetensors.torch import load_file\n\n# setting the visible cuda device (ensuring index 6 exists on your system)\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"6\"\n\n# defining all perspectives used for multi-perspective summarization\nPERSPECTIVES = [\"INFORMATION\", \"SUGGESTION\", \"EXPERIENCE\", \"QUESTION\", \"CAUSE\"]\n\n# defining helper function for cleaning summary text by filtering out empty or irrelevant strings\ndef clean_summary(text):\n    if not text or not isinstance(text, str):\n        return \"\"\n    stripped = text.strip()\n    if stripped.lower() in [\"false\", \"true\", \"not_duplicate\", \"duplicate\", \"n/a\", \"\", \"no summary available.\"]:\n        return \"\"\n    return stripped\n\n# defining function to format raw examples into consistent format with cleaned perspective summaries\ndef format_example(example):\n    input_text = example[\"input\"].strip()\n    output_sections = example[\"output\"].strip().split(\"\\n\")\n    formatted_lines = []\n    for label in PERSPECTIVES:\n        matches = [line for line in output_sections if line.startswith(f\"{label} SUMMARY:\")]\n        if matches:\n            summary = clean_summary(matches[0].split(\"SUMMARY:\", 1)[-1])\n            if summary:\n                formatted_lines.append(f\"{label} SUMMARY: {summary}\")\n    return {\"input\": input_text, \"output\": \"\\n\".join(formatted_lines)}\n\n# loading tokenizer and base bart model\nmodel_name = \"facebook/bart-large-cnn\"\ntokenizer = BartTokenizer.from_pretrained(model_name)\nbase_model = BartForConditionalGeneration.from_pretrained(model_name)\n\n# applying lora (low-rank adaptation) for parameter-efficient fine-tuning\npeft_config = LoraConfig(\n    task_type=TaskType.SEQ_2_SEQ_LM,\n    inference_mode=False,\n    r=8,\n    lora_alpha=32,\n    lora_dropout=0.1\n)\nmodel = get_peft_model(base_model, peft_config)\n\n# loading lora weights from safetensors file\nlora_weights_path = \"./bart-optimized/adapter_model.safetensors\"\nlora_weights = load_file(lora_weights_path)\nmodel.load_state_dict(lora_weights, strict=False)\nmodel.train()\n\n# loading raw dataset and formatting it for training\nraw_data = load_dataset(\"json\", data_files={\"train\": \"./hard_examples.json\"})[\"train\"]\nformatted_data = [format_example(ex) for ex in tqdm(raw_data, desc=\"formatting hard examples\")]\ndataset = Dataset.from_list(formatted_data)\n\n# defining tokenization function for input-output pairs\ndef preprocess_function(examples):\n    model_inputs = tokenizer(\n        examples[\"input\"],\n        max_length=512,\n        padding=\"max_length\",\n        truncation=True,\n    )\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(\n            examples[\"output\"],\n            max_length=256,\n            padding=\"max_length\",\n            truncation=True,\n        )\n    # masking pad tokens in labels for loss calculation\n    labels_input_ids = labels[\"input_ids\"]\n    labels_input_ids = [\n        [(l if l != tokenizer.pad_token_id else -100) for l in label_seq]\n        for label_seq in labels_input_ids\n    ]\n    model_inputs[\"labels\"] = labels_input_ids\n    return model_inputs\n\n# applying preprocessing and removing original columns\ntokenized = dataset.map(preprocess_function, batched=True)\ntokenized = tokenized.remove_columns(dataset.column_names)\n\n# defining training arguments for trainer api\ntraining_args = TrainingArguments(\n    output_dir=\"./hard_example_lora\",\n    do_eval=True,\n    eval_steps=ceil(len(tokenized) / 4),\n    save_strategy=\"epoch\",\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    num_train_epochs=3,\n    save_total_limit=2,\n    logging_steps=10,\n    fp16=False,\n    local_rank=-1,\n    label_names=[\"labels\"],\n    logging_dir=\"./logs\",\n    report_to=[],  # disabling reporting to external services like wandb\n)\n\n# initializing trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized,\n    tokenizer=tokenizer\n)\n\n# fine-tuning the model and saving artifacts\ntrainer.train()\nmodel.save_pretrained(\"./bart-lora-hard\")\ntokenizer.save_pretrained(\"./bart-lora-hard\")\ntorch.save(model.state_dict(), \"bart-lora-hard.pt\")\n\n# to save lora weights in safetensors format instead:\n# from safetensors.torch import save_file\n# save_file(model.state_dict(), \"bart-lora-hard.safetensors\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport torch\nimport torch.nn as nn\nimport numpy as np\nfrom tqdm import tqdm\n\n# For evaluation\nimport evaluate\n\n\n# --- Constants & Mappings ---\n\nPERSPECTIVES = [\"INFORMATION\", \"SUGGESTION\", \"EXPERIENCE\", \"QUESTION\", \"CAUSE\"]\nBIO_TAGS = [\"O\"] + [f\"{tag}-{p}\" for p in PERSPECTIVES for tag in [\"B\", \"I\"]]\nperspective2id = {p: i for i, p in enumerate(PERSPECTIVES)}\nid2perspective = {i: p for p, i in perspective2id.items()}\nbio2id = {t: i for i, t in enumerate(BIO_TAGS)}\nid2bio = {i: t for t, i in bio2id.items()}\n\n\ndef load_json(path):\n    with open(path, \"r\") as f:\n        return json.load(f)\n\ndef join_answers(entry):\n    answers = entry.get(\"answers\", [])\n    if isinstance(answers, str):\n        return answers.strip()\n    if isinstance(answers, list):\n        return \" \".join(a for a in answers if isinstance(a, str)).strip()\n    return \"\"\n\ndef get_reference_summaries(example):\n    \n    # Extract reference summaries from the test example.\n    # sssuming each example may contain a \"labelled_summaries\" field with keys like \"INFORMATION_SUMMARY\".\n    refs = {}\n    labelled_summaries = example.get(\"labelled_summaries\", {})\n    for perspective in PERSPECTIVES:\n        key = f\"{perspective}_SUMMARY\"\n        ref = labelled_summaries.get(key, \"\").strip()\n        if ref and ref.lower() not in [\"false\", \"true\", \"not_duplicate\", \"n/a\", \"duplicate\"]:\n            refs[perspective] = ref\n    return refs\n\n\n\n# --- Classifier Model ---\n\nfrom transformers import AutoTokenizer, AutoModel\n\nclass DualHeadClassifier(nn.Module):\n    def __init__(self, model_name=\"roberta-base\", num_perspectives=5, num_span_tags=len(BIO_TAGS)):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n        hidden_size = self.encoder.config.hidden_size\n        self.classifier = nn.Linear(hidden_size, num_perspectives)\n        self.tagger = nn.Linear(hidden_size, num_span_tags)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden = outputs.last_hidden_state\n        cls_token = last_hidden[:, 0, :]\n        cls_logits = self.classifier(self.dropout(cls_token))\n        tag_logits = self.tagger(self.dropout(last_hidden))\n        return cls_logits, tag_logits\n\n\n\n# --- Generator Function ---\n\nfrom transformers import BartTokenizer, BartForConditionalGeneration\n\ndef generate_summary_for_perspective(input_text, perspective, generator_model, generator_tokenizer, device):\n    prompt = (\n        f\"Generate a {perspective} summary:\\n\"\n        f\"{input_text}\\n\"\n        f\"Provide a clear and structured {perspective.lower()} summary.\"\n    )\n    inputs = generator_tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n    input_ids = inputs.input_ids.to(device)\n    output_ids = generator_model.generate(input_ids=input_ids, max_length=150, num_beams=5)\n    summary = generator_tokenizer.decode(output_ids[0], skip_special_tokens=True)\n    return summary.strip()\n\n\n\n# --- Evaluation Function ---\n\ndef evaluate_predictions(pipeline_results):\n    # load evaluation metrics\n    bleu_metric = evaluate.load(\"sacrebleu\")\n    bertscore_metric = evaluate.load(\"bertscore\")\n   \n    # initialize results container per perspective.\n    eval_results = {p: {\"references\": [], \"predictions\": []} for p in PERSPECTIVES}\n   \n    for item in pipeline_results:\n        # pipeline_results items include a \"reference_summaries\" field (if available)\n        ref_summaries = item.get(\"reference_summaries\", {})\n        pred_summaries = item.get(\"generated_summaries\", {})\n        for perspective in PERSPECTIVES:\n            if perspective in ref_summaries and perspective in pred_summaries:\n                eval_results[perspective][\"references\"].append(ref_summaries[perspective])\n                eval_results[perspective][\"predictions\"].append(pred_summaries[perspective])\n   \n    # compute BLEU and BERTScore for each perspective\n    for perspective in PERSPECTIVES:\n        refs = eval_results[perspective][\"references\"]\n        preds = eval_results[perspective][\"predictions\"]\n        if refs and preds:\n            bleu_score = bleu_metric.compute(\n                predictions=preds,\n                references=[[ref] for ref in refs]\n            )[\"score\"]\n            bert_result = bertscore_metric.compute(\n                predictions=preds,\n                references=refs,\n                lang=\"en\"\n            )\n            bert_avg = np.mean(bert_result[\"f1\"])\n            print(\"{} - BLEU: {:.8f}, BERTScore: {:.4f}\".format(perspective, bleu_score, bert_avg))\n        else:\n            print(\"{} - Not enough data for evaluation.\".format(perspective))\n\n\n    \n# ---------------------------\n# --- Main Pipeline ---\n# ---------------------------\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# ---------- classifier model and tokenizer loading----------\n    \nclassifier_model_path = \"/kaggle/input/dual-classifier-model/pytorch/default/1/dual_classifier_final.pt\"\nclassifier_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\nclassifier_model = DualHeadClassifier(model_name=\"roberta-base\",\n                                      num_perspectives=len(PERSPECTIVES),\n                                      num_span_tags=len(BIO_TAGS))\nclassifier_state = torch.load(classifier_model_path, map_location=device)\nclassifier_model.load_state_dict(classifier_state)\nclassifier_model.to(device)\nclassifier_model.eval()\n\n\n# ---------- generator model and tokenizer loading ----------\n\ngenerator_model_path = \"/kaggle/input/bard-lora-hard-2/pytorch/default/1\"\ngenerator_tokenizer = BartTokenizer.from_pretrained(generator_model_path)\ngenerator_model = BartForConditionalGeneration.from_pretrained(generator_model_path)\ngenerator_model.to(device)\ngenerator_model.eval()\n\ntest_data_path = \"/kaggle/input/nlp-project/test_project.json\"\ntest_data = load_json(test_data_path)\n# test_data = test_data[:int(0.01 * len(test_data))]\n\npipeline_results = []\n\nfor item in tqdm(test_data, desc=\"Processing Test Examples\"):\n    question = item.get(\"question\", \"\").strip()\n    answer = join_answers(item)\n\n    # reference summaries\n    reference_summaries = get_reference_summaries(item)\n\n    if not question or not answer:\n        continue\n\n    # combine text input as in classifier prediction\n    text = f\"Question: {question} Answer: {answer}\"\n\n    # ---------- classifier prediction ----------\n    \n    encoding = classifier_tokenizer(\n        text,\n        return_tensors=\"pt\",\n        padding=\"max_length\",\n        truncation=True,\n        max_length=512,\n        return_offsets_mapping=True\n    )\n    input_ids = encoding[\"input_ids\"].to(device)\n    attention_mask = encoding[\"attention_mask\"].to(device)\n\n    \n    with torch.no_grad():\n        cls_logits, _ = classifier_model(input_ids, attention_mask)\n        # apply sigmoid to get probabilities for multi-label classification\n        pred_probs = torch.sigmoid(cls_logits).squeeze(0).cpu().numpy()\n\n    # select predicted perspectives with probability > 0.5\n    predicted_perspectives = [id2perspective[i] for i, prob in enumerate(pred_probs) if prob > 0.5]\n\n\n    \n    # ---------- generator summary for each predicted perspective ----------\n    \n    generated_summaries = {}\n    if predicted_perspectives:\n        for perspective in predicted_perspectives:\n            summary = generate_summary_for_perspective(text, perspective, generator_model, generator_tokenizer, device)\n            generated_summaries[perspective] = summary\n    else:\n        # in case no perspective exceeds threshold, generate summaries for all\n        for perspective in PERSPECTIVES:\n            summary = generate_summary_for_perspective(text, perspective, generator_model, generator_tokenizer, device)\n            generated_summaries[perspective] = summary\n\n    pipeline_results.append({\n        \"question\": question,\n        \"answer\": answer,\n        \"predicted_perspectives\": predicted_perspectives,\n        \"generated_summaries\": generated_summaries,\n        \"reference_summaries\": reference_summaries\n    })\n\n\n# Saving pipeline results to file \noutput_file = \"pipeline_2_test_predictions.json\"\nwith open(output_file, \"w\") as f:\n    json.dump(pipeline_results, f, indent=2)\nprint(f\"Pipeline complete. Results saved to {output_file}\")\n\n\n# ---------- Evaluatations ----------\n\nevaluate_predictions(pipeline_results)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-14T19:19:30.630616Z","iopub.execute_input":"2025-04-14T19:19:30.631174Z","iopub.status.idle":"2025-04-14T19:46:45.509811Z","shell.execute_reply.started":"2025-04-14T19:19:30.631149Z","shell.execute_reply":"2025-04-14T19:46:45.509147Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_31/1761555408.py:140: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  classifier_state = torch.load(classifier_model_path, map_location=device)\nProcessing Test Examples: 100%|██████████| 640/640 [26:48<00:00,  2.51s/it]\n","output_type":"stream"},{"name":"stdout","text":"Pipeline complete. Results saved to pipeline_2_test_predictions.json\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"INFORMATION - BLEU: 10.43987691, BERTScore: 0.8770\nSUGGESTION - BLEU: 6.43254635, BERTScore: 0.8635\nEXPERIENCE - BLEU: 3.91803737, BERTScore: 0.8465\nQUESTION - BLEU: 0.50806114, BERTScore: 0.8376\nCAUSE - BLEU: 6.74203294, BERTScore: 0.8676\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}