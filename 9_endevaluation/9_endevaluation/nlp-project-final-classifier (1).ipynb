{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11358776,"sourceType":"datasetVersion","datasetId":7108970},{"sourceId":11402371,"sourceType":"datasetVersion","datasetId":7141816},{"sourceId":336026,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":281254,"modelId":302144},{"sourceId":336043,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":281270,"modelId":302160}],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"print(\"HELLO WORLD\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-14T09:33:35.897814Z","iopub.execute_input":"2025-04-14T09:33:35.898022Z","iopub.status.idle":"2025-04-14T09:33:35.904642Z","shell.execute_reply.started":"2025-04-14T09:33:35.898003Z","shell.execute_reply":"2025-04-14T09:33:35.903576Z"}},"outputs":[{"name":"stdout","text":"HELLO WORLD\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import json\nimport numpy as np\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, get_scheduler\nfrom sklearn.metrics import classification_report\nfrom tqdm import tqdm\n\n#Constants\nPERSPECTIVES = [\"INFORMATION\", \"SUGGESTION\", \"EXPERIENCE\", \"QUESTION\", \"CAUSE\"]\nBIO_TAGS = [\"O\"] + [f\"{tag}-{p}\" for p in PERSPECTIVES for tag in [\"B\", \"I\"]]\nperspective2id = {p: i for i, p in enumerate(PERSPECTIVES)}\nbio2id = {t: i for i, t in enumerate(BIO_TAGS)}\nid2bio = {i: t for t, i in bio2id.items()}\n\n# Dataset \nclass DualHeadDataset(Dataset):\n    def __init__(self, data, tokenizer, max_length=512):\n        self.data = data\n        self.tokenizer = tokenizer\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        item = self.data[idx]\n        text = f\"Question: {item['question']} Answer: {item['answer']}\"\n        encoding = self.tokenizer(text, padding=\"max_length\", truncation=True,\n                                  max_length=self.max_length, return_offsets_mapping=True)\n        input_ids = encoding[\"input_ids\"]\n        attention_mask = encoding[\"attention_mask\"]\n        offsets = encoding[\"offset_mapping\"]\n        del encoding[\"offset_mapping\"]\n\n        # Classification labels\n        perspective_labels = [0] * len(PERSPECTIVES)\n        span_dict = item.get(\"labelled_answer_spans\", {})\n        for p, spans in span_dict.items():\n            if p in perspective2id:\n                perspective_labels[perspective2id[p]] = 1\n\n        # BIO span tagging\n        span_labels = [\"O\"] * len(input_ids)\n        answer_text = item[\"answer\"]\n        for p, spans in span_dict.items():\n            if p not in perspective2id:\n                continue\n            for span_entry in spans:\n                span_txt = span_entry.get(\"txt\", \"\").strip()\n                start_idx = answer_text.find(span_txt)\n                if start_idx == -1:\n                    continue\n                end_idx = start_idx + len(span_txt)\n                for i, (start, end) in enumerate(offsets):\n                    if start == 0 and end == 0:\n                        continue  # special tokens\n                    if end <= start_idx or start >= end_idx:\n                        continue\n                    tag = f\"B-{p}\" if start == start_idx else f\"I-{p}\"\n                    span_labels[i] = tag\n\n        span_label_ids = [bio2id.get(tag, 0) for tag in span_labels]\n\n        return {\n            \"input_ids\": torch.tensor(input_ids),\n            \"attention_mask\": torch.tensor(attention_mask),\n            \"perspective_labels\": torch.tensor(perspective_labels, dtype=torch.float),\n            \"span_labels\": torch.tensor(span_label_ids)\n        }\n\n# Model \nclass DualHeadClassifier(nn.Module):\n    def __init__(self, model_name=\"roberta-base\", num_perspectives=5, num_span_tags=len(BIO_TAGS)):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n        hidden_size = self.encoder.config.hidden_size\n        self.classifier = nn.Linear(hidden_size, num_perspectives)\n        self.tagger = nn.Linear(hidden_size, num_span_tags)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden = outputs.last_hidden_state\n        cls_token = last_hidden[:, 0, :]\n        cls_logits = self.classifier(self.dropout(cls_token))\n        tag_logits = self.tagger(self.dropout(last_hidden))\n        return cls_logits, tag_logits\n\n# Utilities \ndef load_json(path):\n    with open(path) as f:\n        return json.load(f)\n\ndef compute_metrics(preds, labels, threshold=0.5):\n    preds_bin = (preds >= threshold).astype(int)\n    report = classification_report(labels, preds_bin, target_names=PERSPECTIVES, zero_division=0, output_dict=True)\n    print(json.dumps(report, indent=2))\n    return report\n\n# Training \ndef train(model, dataloader, optimizer, scheduler, loss_fn_cls, loss_fn_tag, device, span_weight=0.5):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(dataloader, desc=\"Training\"):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        perspective_labels = batch[\"perspective_labels\"].to(device)\n        span_labels = batch[\"span_labels\"].to(device)\n\n        cls_logits, tag_logits = model(input_ids, attention_mask)\n\n        loss_cls = loss_fn_cls(cls_logits, perspective_labels)\n        loss_tag = loss_fn_tag(tag_logits.view(-1, tag_logits.shape[-1]), span_labels.view(-1))\n        loss = loss_cls + span_weight * loss_tag\n\n        if torch.isnan(loss):\n            print(\"Skipping NaN loss batch\")\n            continue\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        total_loss += loss.item()\n    return total_loss / len(dataloader)\n\n# Evaluation \ndef evaluate(model, dataloader, device):\n    model.eval()\n    all_preds, all_labels = [], []\n    with torch.no_grad():\n        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n            input_ids = batch[\"input_ids\"].to(device)\n            attention_mask = batch[\"attention_mask\"].to(device)\n            labels = batch[\"perspective_labels\"].cpu().numpy()\n\n            cls_logits, _ = model(input_ids, attention_mask)\n            preds = torch.sigmoid(cls_logits).cpu().numpy()\n\n            all_preds.extend(preds)\n            all_labels.extend(labels)\n\n    compute_metrics(np.array(all_preds), np.array(all_labels))\n\n# Main \ndef join_answers(entry):\n    answers = entry.get(\"answers\", [])\n    if isinstance(answers, str):\n        return answers.strip()\n    if isinstance(answers, list):\n        return \" \".join(a for a in answers if isinstance(a, str)).strip()\n    return \"\"\n\ndef main():\n    model_name = \"roberta-base\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n    raw_train = [ex for ex in load_json(\"/kaggle/input/puma-dataset/NLP_project_dataset/train.json\") if isinstance(ex, dict)]\n    raw_val = [ex for ex in load_json(\"/kaggle/input/puma-dataset/NLP_project_dataset/valid.json\") if isinstance(ex, dict)]\n\n    for entry in raw_train:\n        entry[\"answer\"] = join_answers(entry)\n    for entry in raw_val:\n        entry[\"answer\"] = join_answers(entry)\n\n    train_data = [ex for ex in raw_train if ex.get(\"question\") and ex.get(\"answer\")]\n    val_data = [ex for ex in raw_val if ex.get(\"question\") and ex.get(\"answer\")]\n\n    print(f\"Loaded {len(train_data)} train and {len(val_data)} val before subsampling.\")\n    print(f\"Using {len(train_data)} train and {len(val_data)} validation examples.\")\n\n    train_set = DualHeadDataset(train_data, tokenizer)\n    val_set = DualHeadDataset(val_data, tokenizer)\n    train_loader = DataLoader(train_set, batch_size=8, shuffle=True)\n    val_loader = DataLoader(val_set, batch_size=8)\n\n    model = DualHeadClassifier(model_name=model_name).to(device)\n    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n    scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=len(train_loader) * 3)\n    loss_fn_cls = nn.BCEWithLogitsLoss()\n    loss_fn_tag = nn.CrossEntropyLoss(ignore_index=0)\n\n    for epoch in range(3):\n        print(f\"\\nEpoch {epoch + 1}\")\n        train_loss = train(model, train_loader, optimizer, scheduler, loss_fn_cls, loss_fn_tag, device)\n        print(f\"Train Loss: {train_loss:.4f}\")\n        evaluate(model, val_loader, device)\n\n    torch.save(model.state_dict(), \"dual_classifier_final.pt\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-13T17:58:29.854571Z","iopub.execute_input":"2025-04-13T17:58:29.855290Z","iopub.status.idle":"2025-04-13T18:07:37.869275Z","shell.execute_reply.started":"2025-04-13T17:58:29.855259Z","shell.execute_reply":"2025-04-13T18:07:37.868486Z"}},"outputs":[{"name":"stdout","text":"Loaded 2236 train and 959 val before subsampling.\nUsing 2236 train and 959 validation examples.\n","output_type":"stream"},{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 280/280 [02:45<00:00,  1.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.9225\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 120/120 [00:15<00:00,  7.82it/s]\n","output_type":"stream"},{"name":"stdout","text":"{\n  \"INFORMATION\": {\n    \"precision\": 0.8793324775353016,\n    \"recall\": 0.9319727891156463,\n    \"f1-score\": 0.9048877146631439,\n    \"support\": 735\n  },\n  \"SUGGESTION\": {\n    \"precision\": 0.9152249134948097,\n    \"recall\": 0.8890756302521008,\n    \"f1-score\": 0.9019607843137255,\n    \"support\": 595\n  },\n  \"EXPERIENCE\": {\n    \"precision\": 0.8821548821548821,\n    \"recall\": 0.8291139240506329,\n    \"f1-score\": 0.8548123980424144,\n    \"support\": 316\n  },\n  \"QUESTION\": {\n    \"precision\": 1.0,\n    \"recall\": 0.00980392156862745,\n    \"f1-score\": 0.01941747572815534,\n    \"support\": 102\n  },\n  \"CAUSE\": {\n    \"precision\": 0.5217391304347826,\n    \"recall\": 0.5179856115107914,\n    \"f1-score\": 0.5198555956678701,\n    \"support\": 139\n  },\n  \"micro avg\": {\n    \"precision\": 0.8639152258784161,\n    \"recall\": 0.8208797032326444,\n    \"f1-score\": 0.8418478260869565,\n    \"support\": 1887\n  },\n  \"macro avg\": {\n    \"precision\": 0.8396902807239552,\n    \"recall\": 0.6355903752995598,\n    \"f1-score\": 0.6401867936830618,\n    \"support\": 1887\n  },\n  \"weighted avg\": {\n    \"precision\": 0.8713041210435803,\n    \"recall\": 0.8208797032326444,\n    \"f1-score\": 0.8193536645721178,\n    \"support\": 1887\n  },\n  \"samples avg\": {\n    \"precision\": 0.8889468196037539,\n    \"recall\": 0.85950643030935,\n    \"f1-score\": 0.848452422331463,\n    \"support\": 1887\n  }\n}\n\nEpoch 2\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 280/280 [02:46<00:00,  1.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.6541\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 120/120 [00:15<00:00,  7.75it/s]\n","output_type":"stream"},{"name":"stdout","text":"{\n  \"INFORMATION\": {\n    \"precision\": 0.8476977567886659,\n    \"recall\": 0.9768707482993197,\n    \"f1-score\": 0.9077117572692794,\n    \"support\": 735\n  },\n  \"SUGGESTION\": {\n    \"precision\": 0.8543543543543544,\n    \"recall\": 0.9563025210084034,\n    \"f1-score\": 0.9024583663758923,\n    \"support\": 595\n  },\n  \"EXPERIENCE\": {\n    \"precision\": 0.8267045454545454,\n    \"recall\": 0.9208860759493671,\n    \"f1-score\": 0.87125748502994,\n    \"support\": 316\n  },\n  \"QUESTION\": {\n    \"precision\": 0.8947368421052632,\n    \"recall\": 0.3333333333333333,\n    \"f1-score\": 0.48571428571428565,\n    \"support\": 102\n  },\n  \"CAUSE\": {\n    \"precision\": 0.5850340136054422,\n    \"recall\": 0.6187050359712231,\n    \"f1-score\": 0.6013986013986015,\n    \"support\": 139\n  },\n  \"micro avg\": {\n    \"precision\": 0.8282926829268292,\n    \"recall\": 0.8998410174880763,\n    \"f1-score\": 0.8625857251714503,\n    \"support\": 1887\n  },\n  \"macro avg\": {\n    \"precision\": 0.8017055024616543,\n    \"recall\": 0.7612195429123294,\n    \"f1-score\": 0.7537080991575997,\n    \"support\": 1887\n  },\n  \"weighted avg\": {\n    \"precision\": 0.8294754712400847,\n    \"recall\": 0.8998410174880763,\n    \"f1-score\": 0.8545763103303128,\n    \"support\": 1887\n  },\n  \"samples avg\": {\n    \"precision\": 0.8557351407716371,\n    \"recall\": 0.9218804310045186,\n    \"f1-score\": 0.8641888872337254,\n    \"support\": 1887\n  }\n}\n\nEpoch 3\n","output_type":"stream"},{"name":"stderr","text":"Training: 100%|██████████| 280/280 [02:47<00:00,  1.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Train Loss: 0.5440\n","output_type":"stream"},{"name":"stderr","text":"Evaluating: 100%|██████████| 120/120 [00:15<00:00,  7.76it/s]\n","output_type":"stream"},{"name":"stdout","text":"{\n  \"INFORMATION\": {\n    \"precision\": 0.8754716981132076,\n    \"recall\": 0.9469387755102041,\n    \"f1-score\": 0.9098039215686275,\n    \"support\": 735\n  },\n  \"SUGGESTION\": {\n    \"precision\": 0.8938906752411575,\n    \"recall\": 0.934453781512605,\n    \"f1-score\": 0.913722267871816,\n    \"support\": 595\n  },\n  \"EXPERIENCE\": {\n    \"precision\": 0.8502994011976048,\n    \"recall\": 0.8987341772151899,\n    \"f1-score\": 0.8738461538461538,\n    \"support\": 316\n  },\n  \"QUESTION\": {\n    \"precision\": 0.8545454545454545,\n    \"recall\": 0.46078431372549017,\n    \"f1-score\": 0.5987261146496815,\n    \"support\": 102\n  },\n  \"CAUSE\": {\n    \"precision\": 0.65,\n    \"recall\": 0.5611510791366906,\n    \"f1-score\": 0.6023166023166023,\n    \"support\": 139\n  },\n  \"micro avg\": {\n    \"precision\": 0.8624091381100727,\n    \"recall\": 0.8802331743508214,\n    \"f1-score\": 0.8712300026226069,\n    \"support\": 1887\n  },\n  \"macro avg\": {\n    \"precision\": 0.8248414458194849,\n    \"recall\": 0.760412425420036,\n    \"f1-score\": 0.7796830120505762,\n    \"support\": 1887\n  },\n  \"weighted avg\": {\n    \"precision\": 0.8593242697529283,\n    \"recall\": 0.8802331743508214,\n    \"f1-score\": 0.8655527757118875,\n    \"support\": 1887\n  },\n  \"samples avg\": {\n    \"precision\": 0.8839589850538755,\n    \"recall\": 0.9017553006604101,\n    \"f1-score\": 0.8715891222669115,\n    \"support\": 1887\n  }\n}\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nimport torch.nn as nn\nfrom transformers import AutoTokenizer, AutoModel\nfrom tqdm import tqdm\n\n#Constants\nPERSPECTIVES = [\"INFORMATION\", \"SUGGESTION\", \"EXPERIENCE\", \"QUESTION\", \"CAUSE\"]\nBIO_TAGS = [\"O\"] + [f\"{tag}-{p}\" for p in PERSPECTIVES for tag in [\"B\", \"I\"]]\nperspective2id = {p: i for i, p in enumerate(PERSPECTIVES)}\nid2perspective = {i: p for p, i in perspective2id.items()}\nbio2id = {t: i for i, t in enumerate(BIO_TAGS)}\nid2bio = {i: t for t, i in bio2id.items()}\n\ndef load_json(path):\n    with open(path) as f:\n        return json.load(f)\n\ndef join_answers(entry):\n    answers = entry.get(\"answers\", [])\n    if isinstance(answers, str):\n        return answers.strip()\n    if isinstance(answers, list):\n        return \" \".join(a for a in answers if isinstance(a, str)).strip()\n    return \"\"\n\nclass DualHeadClassifier(nn.Module):\n    def __init__(self, model_name=\"roberta-base\", num_perspectives=5, num_span_tags=len(BIO_TAGS)):\n        super().__init__()\n        self.encoder = AutoModel.from_pretrained(model_name)\n        self.dropout = nn.Dropout(0.3)\n        hidden_size = self.encoder.config.hidden_size\n        self.classifier = nn.Linear(hidden_size, num_perspectives)\n        self.tagger = nn.Linear(hidden_size, num_span_tags)\n\n    def forward(self, input_ids, attention_mask):\n        outputs = self.encoder(input_ids=input_ids, attention_mask=attention_mask)\n        last_hidden = outputs.last_hidden_state\n        cls_token = last_hidden[:, 0, :]\n        cls_logits = self.classifier(self.dropout(cls_token))\n        tag_logits = self.tagger(self.dropout(last_hidden))\n        return cls_logits, tag_logits\n\n# Span decoding \ndef decode_bio(tags, offsets, input_ids, tokenizer):\n    spans = {p: [] for p in PERSPECTIVES}\n    current_tag = None\n    current_tokens = []\n    for i, tag_id in enumerate(tags):\n        tag = id2bio.get(tag_id, \"O\")\n        if tag == \"O\":\n            if current_tag and current_tokens:\n                span_text = tokenizer.decode(input_ids[current_tokens[0]:current_tokens[-1]+1], skip_special_tokens=True).strip()\n                spans[current_tag].append(span_text)\n                current_tag = None\n                current_tokens = []\n            continue\n        prefix, label = tag.split(\"-\")\n        if prefix == \"B\":\n            if current_tag and current_tokens:\n                span_text = tokenizer.decode(input_ids[current_tokens[0]:current_tokens[-1]+1], skip_special_tokens=True).strip()\n                spans[current_tag].append(span_text)\n            current_tag = label\n            current_tokens = [i]\n        elif prefix == \"I\" and current_tag == label:\n            current_tokens.append(i)\n        else:\n            if current_tag and current_tokens:\n                span_text = tokenizer.decode(input_ids[current_tokens[0]:current_tokens[-1]+1], skip_special_tokens=True).strip()\n                spans[current_tag].append(span_text)\n            current_tag = None\n            current_tokens = []\n    if current_tag and current_tokens:\n        span_text = tokenizer.decode(input_ids[current_tokens[0]:current_tokens[-1]+1], skip_special_tokens=True).strip()\n        spans[current_tag].append(span_text)\n    return {k: v for k, v in spans.items() if v}\n\n# Prediction loop \ndef predict(model, data, tokenizer, device):\n    model.eval()\n    results = []\n    for item in tqdm(data, desc=\"Predicting\"):\n        question = item[\"question\"]\n        answer = join_answers(item)\n        text = f\"Question: {question} Answer: {answer}\"\n        encoding = tokenizer(text, return_tensors=\"pt\", padding=\"max_length\", truncation=True, max_length=512, return_offsets_mapping=True)\n        input_ids = encoding[\"input_ids\"].to(device)\n        attention_mask = encoding[\"attention_mask\"].to(device)\n        offsets = encoding[\"offset_mapping\"][0].tolist()\n\n        with torch.no_grad():\n            cls_logits, tag_logits = model(input_ids, attention_mask)\n            pred_labels = torch.sigmoid(cls_logits).squeeze(0).cpu().numpy()\n            pred_bio = torch.argmax(tag_logits, dim=-1).squeeze(0).cpu().numpy()\n\n        predicted_perspectives = [id2perspective[i] for i, prob in enumerate(pred_labels) if prob > 0.5]\n        spans = decode_bio(pred_bio, offsets, input_ids[0].tolist(), tokenizer)\n\n        results.append({\n            \"question\": question,\n            \"answer\": answer,\n            \"predicted_perspectives\": predicted_perspectives,\n            \"predicted_spans\": spans\n        })\n    return results\n\n# main \ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\nmodel = DualHeadClassifier()\nmodel.load_state_dict(torch.load(\"dual_classifier_full.pt\", map_location=device))\nmodel.to(device)\n\ntest_data = load_json(\"/kaggle/input/puma-dataset/NLP_project_dataset/test.json\")\nfor entry in test_data:\n    entry[\"answer\"] = join_answers(entry)\ntest_data = [ex for ex in test_data if ex.get(\"question\") and ex.get(\"answer\")]\n\nprint(f\"Loaded {len(test_data)} test samples.\")\npredictions = predict(model, test_data, tokenizer, device)\n\n# Save predictions\nwith open(\"predictions.json\", \"w\") as f:\n    json.dump(predictions, f, indent=2)\n\nprint(\"✅ Predictions saved to predictions.json\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-10T18:48:40.709337Z","iopub.execute_input":"2025-04-10T18:48:40.709932Z","iopub.status.idle":"2025-04-10T18:48:55.340330Z","shell.execute_reply.started":"2025-04-10T18:48:40.709906Z","shell.execute_reply":"2025-04-10T18:48:55.339562Z"}},"outputs":[{"name":"stderr","text":"Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/tmp/ipykernel_31/2035180299.py:113: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load(\"dual_classifier_full.pt\", map_location=device))\n","output_type":"stream"},{"name":"stdout","text":"Loaded 640 test samples.\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|██████████| 640/640 [00:13<00:00, 48.97it/s]","output_type":"stream"},{"name":"stdout","text":"✅ Predictions saved to predictions.json\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -q peft accelerate evaluate datasets transformers sacrebleu bert-score\n!pip install -U transformers\n!pip install datasets\n!pip install evaluate\n!pip install bert-score\n!pip install sacrebleu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-12T18:37:33.791016Z","iopub.execute_input":"2025-04-12T18:37:33.791296Z","iopub.status.idle":"2025-04-12T18:38:49.418484Z","shell.execute_reply.started":"2025-04-12T18:37:33.791279Z","shell.execute_reply":"2025-04-12T18:38:49.417549Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}